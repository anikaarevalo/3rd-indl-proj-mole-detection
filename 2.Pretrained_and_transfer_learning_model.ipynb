{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14718be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model for the skin cancer classifier\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "# K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "# The paths for the training and validation images\n",
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring a few useful values\n",
    "num_train_samples = 9013\n",
    "num_val_samples = 1002\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68292112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring how many steps are needed in an iteration\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab624cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up generators\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=train_batch_size)\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size)\n",
    "\n",
    "test_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a MobileNet model\n",
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the layers in the model\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918860d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the weights of the layers that we aren't training (training the last 23)\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba46726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# Defining Top2 and Top3 Accuracy\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a07b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "\n",
    "# Adding weights to make the model more sensitive to melanoma\n",
    "class_weights={\n",
    "    0: 1.0,  # akiec\n",
    "    1: 1.0,  # bcc\n",
    "    2: 1.0,  # bkl\n",
    "    3: 1.0,  # df\n",
    "    4: 3.0,  # mel\n",
    "    5: 1.0,  # nv\n",
    "    6: 1.0,  # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69054573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the filepath for the saved model\n",
    "filepath = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25720fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring a checkpoint to save the best version of the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ede6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef163d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch=train_steps,\n",
    "                              class_weight=class_weights,\n",
    "                              validation_data=valid_batches,\n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "# Evaluation of the last epoch\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate_generator(test_batches, steps=val_steps)\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating of the best epoch\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
    "model.evaluate_generator(test_batches, steps=val_steps)\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n",
    "print('val_top_2_acc:', val_top_2_acc)\n",
    "print('val_top_3_acc:', val_top_3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a confusion matrix of the test images\n",
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = model.predict_generator(test_batches, steps=val_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring a function for plotting the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
    "\n",
    "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
