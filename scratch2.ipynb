{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0b4de3",
   "metadata": {},
   "source": [
    "## Pre-trained model usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfce3b",
   "metadata": {},
   "source": [
    "### Importing an existing deep learning model for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ed691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model for the skin cancer classifier\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "#from tensorflow.keras.layers.core import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e28a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "# Tensorflow is installed without CUDA support\n",
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ea380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths for the training and validation images\n",
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring a few useful values\n",
    "num_train_samples = 9013\n",
    "num_val_samples = 1002\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring how many steps are needed in an iteration\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da79e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up generators\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=train_batch_size)\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size)\n",
    "\n",
    "test_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df149513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising a MobileNet pre-trained model from Keras and passing it to model object\n",
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying a summary of the layers in the model\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ffb3d",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d82f9",
   "metadata": {},
   "source": [
    "### Modifying MobileNet model architecture to retrain it on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245a2c4",
   "metadata": {},
   "source": [
    "The **MobileNet pre-trained model** has millions of connections that has already been trained on a large data set. It is reliable at identifying different features hence there is **only a need to retrain a part of it** by 'freezing' its first few layers. **After adding a fully connected layer and through only training the last few layers, a 'new' model is obtained** that can effectively identify basic features and make predictions on relevant new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23755b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the model\n",
    "# Excluding the last 5 layers of the model\n",
    "x = mobile.layers[-6].output\n",
    "# Adding a dropout and dense layer for predictions\n",
    "x = Dropout(0.25)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new model with the new outputs\n",
    "model = Model(inputs=mobile.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing a summary of the new layers in the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the weights of the layers that we aren't training (training the last 23 to avoid memory problem).\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras import Model\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89e196",
   "metadata": {},
   "source": [
    "### Training the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# Defining Top2 and Top3 Accuracy\n",
    "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "\n",
    "# Adding weights to make the model more sensitive to melanoma, which is a type of skin cancer\n",
    "class_weights={\n",
    "    0: 1.0,  # akiec\n",
    "    1: 1.0,  # bcc\n",
    "    2: 1.0,  # bkl\n",
    "    3: 1.0,  # df\n",
    "    4: 3.0,  # mel\n",
    "    5: 1.0,  # nv\n",
    "    6: 1.0,  # vasc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the filepath for the saved model\n",
    "filepath = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring a checkpoint to save the best version of the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81137f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch=train_steps,\n",
    "                              class_weight=class_weights,\n",
    "                              validation_data=valid_batches,\n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=5,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf185a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
